{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tbparse import SummaryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "TB_LOGS_ROOT = '../tb_logs'  # Download all logs manually before running notebook.\n",
    "PLOTS_DIR = '../plots'\n",
    "SHOW_PLOTS = True\n",
    "\n",
    "if not os.path.exists(PLOTS_DIR):\n",
    "  os.makedirs(PLOTS_DIR)\n",
    "\n",
    "\n",
    "def read_tb_logs_to_dfs(log_dir_name: str) -> dict[str, pd.DataFrame]:\n",
    "    reader = SummaryReader(os.path.join(TB_LOGS_ROOT, log_dir_name))\n",
    "    df = reader.scalars\n",
    "\n",
    "    dataframes = {}\n",
    "    for name in sorted(set(df['tag'])):\n",
    "        separate_df = df[df['tag'] == name]\n",
    "        separate_df.index = np.arange(1, len(separate_df) + 1)\n",
    "        dataframes[name] = separate_df\n",
    "\n",
    "    return dataframes\n",
    "\n",
    "def merge_into_one_df(df_names: list[str], dfs: dict[str, pd.DataFrame]) -> pd.DataFrame:\n",
    "    dfs = {name: dfs[name] for name in df_names}\n",
    "    new_df = pd.DataFrame()\n",
    "    for name, df in dfs.items():\n",
    "        new_df[name] = df['value']\n",
    "\n",
    "    return new_df\n",
    "\n",
    "def plot_metrics(df: pd.DataFrame, metric_to_label: dict[str, str], plot_name: str):\n",
    "    metric_name = 'loss' if 'loss' in next(iter(metric_to_label)) else 'accuracy'\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6.4, 4))\n",
    "    for metric, label in metric_to_label.items():\n",
    "        ax.plot(df.index, df[metric], label=label)\n",
    "    ax.set(xlabel='epoch', ylabel=metric_name)\n",
    "    ax.legend(loc='upper right' if metric_name == 'loss' else 'lower right')\n",
    "    if SHOW_PLOTS:\n",
    "        fig.show()\n",
    "\n",
    "    fig.savefig(os.path.join(PLOTS_DIR, f'{plot_name}.pdf'), bbox_inches='tight')\n",
    "\n",
    "def plot_lightning_logs(log_dir_name: str, model_name: str):\n",
    "    dataframes = read_tb_logs_to_dfs(log_dir_name)\n",
    "\n",
    "    loss_metrics = {\n",
    "        'train_loss_epoch': model_name + ' training loss',\n",
    "        'val_loss_epoch': model_name + ' validation loss'\n",
    "    }\n",
    "    accuracy_metrics = {\n",
    "        'train_accuracy_epoch': model_name + ' training accuracy',\n",
    "        'val_accuracy_epoch': model_name + ' validation accuracy'\n",
    "    }\n",
    "\n",
    "    df = merge_into_one_df(list(loss_metrics.keys()) + list(accuracy_metrics.keys()), dataframes)\n",
    "    plot_metrics(df, loss_metrics, log_dir_name + '_loss')\n",
    "    plot_metrics(df, accuracy_metrics, log_dir_name + '_accuracy')\n",
    "\n",
    "def plot_transformers_logs(log_dir_name: str, model_name: str):\n",
    "    dataframes = read_tb_logs_to_dfs(log_dir_name)\n",
    "\n",
    "    loss_metrics = {\n",
    "        'train/loss': model_name + ' training loss',\n",
    "        'eval/loss': model_name + ' validation loss'\n",
    "    }\n",
    "\n",
    "    df = merge_into_one_df(list(loss_metrics.keys()), dataframes)\n",
    "    plot_metrics(df, loss_metrics, log_dir_name + '_loss')\n",
    "\n",
    "def plot_comparison(\n",
    "    log_dir_names: list[str],\n",
    "    model_names: list[str],\n",
    "    split: str,\n",
    "    metric_name: str,\n",
    "    suffix: str=''\n",
    "):\n",
    "    \"\"\"\n",
    "    :param split: 'train' or 'eval'\n",
    "    :param metric_name: 'loss' or 'accuracy'\n",
    "    :param suffix: Use it to distinguish between plots and to avoid overwriting files.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    for log_dir_name, model_name in zip(log_dir_names, model_names):\n",
    "        dataframes = read_tb_logs_to_dfs(log_dir_name)\n",
    "        if 'train/loss' in dataframes:\n",
    "            df[f'{model_name}_{metric_name}'] = dataframes[f'{split}/{metric_name}']['value']\n",
    "        else:\n",
    "            tmp_split = 'val' if split == 'eval' else split\n",
    "            df[f'{model_name}_{metric_name}'] = dataframes[f'{tmp_split}_{metric_name}_epoch']['value']\n",
    "\n",
    "    split = 'training' if split == 'train' else 'validation'\n",
    "    metrics = {\n",
    "        colname: f'{model_name} {split} {metric_name}'\n",
    "        for colname, model_name in zip(df.columns, model_names)\n",
    "    }\n",
    "\n",
    "    plot_metrics(df, metrics, f'comparison_{split}_{metric_name}_{suffix}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_dir_names = [\n",
    "    'T5_3e-4', 'T5_3e-4_polish_labels',\n",
    "    'mT5-base_5e-4',\n",
    "    'mT5-small_1e-3', 'mT5-small_3langs_1e-3'\n",
    "]\n",
    "model_names = [\n",
    "    'T5', 'T5',\n",
    "    'mT5',\n",
    "    'mT5-small', 'mT5-small'\n",
    "]\n",
    "\n",
    "for log_dir_name, model_name in zip(log_dir_names, model_names):\n",
    "    plot_lightning_logs(log_dir_name, model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_dir_names = [\n",
    "    'xlm-roberta-lr5e5', 'xlm-roberta-lr5e5-combined',\n",
    "    'xlm-v-lr5e5', 'xlm-v-lr5e5-combined',\n",
    "    'herbert_pl_lr5e-5', 'herbert_combined_lr5e-5'\n",
    "]\n",
    "model_names = [\n",
    "    'XLM-RoBERTa', 'XLM-RoBERTa',\n",
    "    'XLM-V', 'XLM-V',\n",
    "    'HerBERT', 'HerBERT'\n",
    "]\n",
    "\n",
    "for log_dir_name, model_name in zip(log_dir_names, model_names):\n",
    "    plot_transformers_logs(log_dir_name, model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_dir_names = ['mT5-small_1e-3', 'xlm-v-lr5e5', 'herbert_pl_lr5e-5']\n",
    "model_names = ['mT5', 'XLM-V', 'HerBERT']\n",
    "\n",
    "plot_comparison(log_dir_names, model_names, 'eval', 'accuracy', 'pl-all_models')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_dir_names = ['mT5-small_3langs_1e-3', 'xlm-v-lr5e5-combined', 'herbert_combined_lr5e-5']\n",
    "model_names = ['mT5', 'XLM-V', 'HerBERT']\n",
    "\n",
    "plot_comparison(log_dir_names, model_names, 'eval', 'accuracy', 'combined-all_models')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_dir_names = ['T5_3e-4', 'mT5-base_5e-4', 'mT5-small_1e-3']\n",
    "model_names = ['T5', 'mT5-base', 'mT5-small']\n",
    "\n",
    "plot_comparison(log_dir_names, model_names, 'eval', 'accuracy', 'pl-T5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_dir_names = ['T5_3e-4', 'T5_3e-4_polish_labels']\n",
    "model_names = ['T5 with English labels', 'T5 with Polish labels']\n",
    "\n",
    "plot_comparison(log_dir_names, model_names, 'eval', 'accuracy', 'polish-labels')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
