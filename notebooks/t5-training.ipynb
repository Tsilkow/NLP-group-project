{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "PATH = '/content/gdrive/MyDrive/NLP-group-project'\n",
    "if not os.path.exists(PATH):\n",
    "    %mkdir -p $PATH\n",
    "\n",
    "%cd $PATH"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install -q --upgrade -r requirements.txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from transformers.modeling_outputs import Seq2SeqLMOutput\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, \\\n",
    "    MT5Tokenizer, MT5ForConditionalGeneration\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from src.dataset import MassiveDatasetT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ClassifierT5(pl.LightningModule):\n",
    "    def __init__(self, tokenizer, model, lr, weight_decay):\n",
    "        super(ClassifierT5, self).__init__()\n",
    "        self._tokenizer = tokenizer\n",
    "        self._model = model\n",
    "        self._lr = lr\n",
    "        self._weight_decay = weight_decay\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(\n",
    "            self._model.parameters(),\n",
    "            lr=self._lr, weight_decay=self._weight_decay\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask=None,\n",
    "        decoder_attention_mask=None,\n",
    "        labels=None\n",
    "    ) -> Seq2SeqLMOutput:\n",
    "        return self._model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            labels=labels,\n",
    "            return_dict=True\n",
    "        )\n",
    "\n",
    "    def _log_metrics(self, metrics, mode):\n",
    "        for metric_name, metric_value in metrics.items():\n",
    "            self.log(\n",
    "                mode + '_' + metric_name,\n",
    "                metric_value,\n",
    "                on_step=True, on_epoch=True, prog_bar=True\n",
    "            )\n",
    "\n",
    "    def _step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        labels = targets['ids'].clone()\n",
    "        labels[labels == self._tokenizer.pad_token_id] = -100\n",
    "        output = self.forward(\n",
    "            inputs['ids'],\n",
    "            attention_mask=inputs['attention_mask'],\n",
    "            decoder_attention_mask=targets['attention_mask'],\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        predicted_labels = self.predict_step(batch)\n",
    "        accuracy = self._compute_accuracy(batch, predicted_labels)\n",
    "\n",
    "        return {'loss': output.loss, 'accuracy': accuracy}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        metrics = self._step(batch)\n",
    "        self._log_metrics(metrics, 'train')\n",
    "        return metrics\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        metrics = self._step(batch)\n",
    "        self._log_metrics(metrics, 'val')\n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        metrics = self._step(batch)\n",
    "        self._log_metrics(metrics, 'test')\n",
    "        return metrics\n",
    "\n",
    "    def predict_step(self, batch, batch_idx=None):\n",
    "        inputs = batch[0]\n",
    "        output = self._model.generate(\n",
    "            inputs['ids'],\n",
    "            attention_mask=inputs['attention_mask'],\n",
    "            do_sample=False,\n",
    "            max_length=MAX_LABEL_LENGTH  # Length of longest label\n",
    "        )\n",
    "        return self._tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "\n",
    "    def _compute_accuracy(self, batch, predicted_labels):\n",
    "        targets = batch[1]\n",
    "        target_labels = self._tokenizer.batch_decode(targets['ids'], skip_special_tokens=True)\n",
    "        accuracy = accuracy_score(y_true=target_labels, y_pred=predicted_labels)\n",
    "        return accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer_t5 = T5Tokenizer.from_pretrained('t5-base', model_max_length=256)\n",
    "model_t5 = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "# tokenizer_t5 = MT5Tokenizer.from_pretrained('google/mt5-small')\n",
    "# model_t5 = MT5ForConditionalGeneration.from_pretrained('google/mt5-small')\n",
    "# tokenizer_t5 = MT5Tokenizer.from_pretrained('google/mt5-base')\n",
    "# model_t5 = MT5ForConditionalGeneration.from_pretrained('google/mt5-base')\n",
    "\n",
    "LANGUAGE = 'pl-PL'\n",
    "# LANGUAGE = 'combined'\n",
    "train_path = os.path.join('data', LANGUAGE, 'train.json')\n",
    "val_path = os.path.join('data', LANGUAGE, 'val.json')\n",
    "test_path = os.path.join('data', LANGUAGE, 'test.json')\n",
    "\n",
    "train_dataset = MassiveDatasetT5(train_path, tokenizer_t5)\n",
    "val_dataset = MassiveDatasetT5(val_path, tokenizer_t5)\n",
    "test_dataset = MassiveDatasetT5(test_path, tokenizer_t5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('data/labels.json', 'r') as file:\n",
    "    labels_values = json.load(file)\n",
    "\n",
    "output = tokenizer_t5(labels_values, padding='longest', return_tensors='pt')\n",
    "MAX_LABEL_LENGTH = output['input_ids'].shape[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "EPOCHS_NUM = 5\n",
    "LEARNING_RATE = 3e-4\n",
    "WEIGHT_DECAY = 1e-2\n",
    "TRAIN_BATCH_SIZE = 50\n",
    "TEST_BATCH_SIZE = 100\n",
    "\n",
    "dataloader_kwargs = {'num_workers': 2, 'pin_memory': True}\n",
    "\n",
    "train_kwargs = {'batch_size': TRAIN_BATCH_SIZE, 'shuffle': True, **dataloader_kwargs}\n",
    "test_kwargs = {'batch_size': TEST_BATCH_SIZE, 'shuffle': False, **dataloader_kwargs}\n",
    "\n",
    "train_loader = DataLoader(train_dataset, **train_kwargs)\n",
    "val_loader = DataLoader(val_dataset, **test_kwargs)\n",
    "test_loader = DataLoader(test_dataset, **test_kwargs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(monitor='val_accuracy_epoch', mode='max')\n",
    "trainer = pl.Trainer(\n",
    "    log_every_n_steps=10,\n",
    "    max_epochs=EPOCHS_NUM,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "classifierT5 = ClassifierT5(\n",
    "    tokenizer=tokenizer_t5,\n",
    "    model=model_t5,\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "trainer.fit(classifierT5, train_loader, val_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.test(classifierT5, test_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
